我们非常欢迎Pull requests和贡献。这里有一个清单，如果能完成就好了。这些任务可能很适合，例如，对进入NLP感兴趣的本科生。关于这些任务的更多细节，请随时给我发电子邮件。

- **启用多GPU训练和预测**. There's a [tutorial](https://medium.com/ai2-blog/tutorial-how-to-train-with-multiple-gpus-in-allennlp-c4d7c17eb6d6) on how to do this.
- **对建模代码进行重构和注释**. Basically all of the modeling is accomplished by enumerating spans, and then running them through unary or binary scoring functions. Because this was written as research code, a lot of functionality is duplicated. Re-factoring could make the code much easier to extend. If interested, email me and I'll provide more info.
- **清理文档**. The documentation could be more organized and concise. In particular, I don't do a great job explaining how to use a pretrained model to make predictons on a new dataset.
- **启用多namespace预测**. Right now, when using a pretrained model to make predictons on a new dataset, the user specifies which label namespace the model should use to make predictions by setting the `dataset` field in the new dataset. Ideally, the user should be able to request predictions for multiple different label namespaces as a flag to `allennlp predict`, for instance. For more information on label namespaces see the information on [multi-dataset training](model.md/#multi-dataset-training).
- **启用1以外的批次大小的训练**. See the final "Problem" in [batching and batch size](model.md#batching-and-batch-size) for more information on why this would be helpful.
